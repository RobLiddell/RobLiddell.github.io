geom_point()
output <- dat|>
select(Xs,Ys)|>
kmeans(4)
dat %>%
mutate(cluster=output$cluster)%>%
mutate(across(c(Group,cluster),~factor(.x))) %>%
ggplot(aes(x=Xs,y=Ys,colour=cluster,shape=Group))+
geom_point()
set.seed(214)
dat <- tibble(Group=c(1:4))|>
mutate(cenX=runif(n=n()),
cenY=runif(n=n()))|>
rowwise()|>
mutate(Xs=list(rnorm(200,cenX,sd=0.05)),
Ys=list(rnorm(200,cenY,sd=0.05)))|>
unnest_longer(col=c(Xs,Ys))
output <- dat|>
select(Xs,Ys)|>
kmeans(4)
datClust <- dat %>%
mutate(cluster=output$cluster)%>%
mutate(across(c(Group,cluster),~factor(.x)))
datClust %>%
ggplot(aes(x=Xs,y=Ys,colour=cluster,shape=Group))+
geom_point()
datClust|>
group_by(cluster)|>
summarise(n())
#####Libraries#####
library(tidyverse)
library(lubridate)
library(DBI)
library(odbc)
con <- dbConnect(odbc(), dsn="LateRecWell") #This connection is specific to my computer and was set through odbc 64 bit settings
dbListTables(con)%>%
str_subset(pattern = "^t")
aa <- edit()
aa
aa <- edit(aa)
aa <- edit(aa)
aa
aa(a:10)
aa(1:10)
aa <- edit(aa)
aa(1:10)
aa <- edit(aa)
aa <- function(x){
return(mean(x)))
aa
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
aa <- function(x){
return(mean(x)))
bb <- function(x){
return(2131)
}
print('adssd','asda')
cat('adssd','asda')
fix(aa)
aa <- function(x){
return(mean(x))
}
fix(aa)
aa
getOption("verbose")
####NLS Pridict####
predictNLS <- function(object,newdata,level = 0.95, nsim = 10000, ...){
require(MASS, quietly = TRUE)
## get right-hand side of formula
RHS <- as.list(object$m$formula())[[3]]
EXPR <- as.expression(RHS)
## all variables in model
VARS <- all.vars(EXPR)
## coefficients
COEF <- coef(object)
## extract predictor variable
predNAME <- setdiff(VARS, names(COEF))
## take fitted values, if 'newdata' is missing
if (missing(newdata)) {
newdata <- eval(object$data)[predNAME]
colnames(newdata) <- predNAME
}
## check that 'newdata' has same name as predVAR
if (names(newdata)[1] != predNAME) stop("newdata should have name '", predNAME, "'!")
## get parameter coefficients
COEF <- coef(object)
## get variance-covariance matrix
VCOV <- vcov(object)
## augment variance-covariance matrix for 'mvrnorm'
## by adding a column/row for 'error in x'
NCOL <- ncol(VCOV)
ADD1 <- c(rep(0, NCOL))
ADD1 <- matrix(ADD1, ncol = 1)
colnames(ADD1) <- predNAME
VCOV <- cbind(VCOV, ADD1)
ADD2 <- c(rep(0, NCOL + 1))
ADD2 <- matrix(ADD2, nrow = 1)
rownames(ADD2) <- predNAME
VCOV <- rbind(VCOV, ADD2)
## iterate over all entries in 'newdata' as in usual 'predict.' functions
NR <- nrow(newdata)
respVEC <- numeric(NR)
seVEC <- numeric(NR)
varPLACE <- ncol(VCOV)
## define counter function
counter <- function (i)
{
if (i%%10 == 0)
cat(i)
else cat(".")
if (i%%50 == 0)
cat("\n")
flush.console()
}
outMAT <- NULL
for (i in 1:NR) {
counter(i)
## get predictor values and optional errors
predVAL <- newdata[i, 1]
if (ncol(newdata) == 2) predERROR <- newdata[i, 2] else predERROR <- 0
names(predVAL) <- predNAME
names(predERROR) <- predNAME
## create mean vector for 'mvrnorm'
MU <- c(COEF, predVAL)
## create variance-covariance matrix for 'mvrnorm'
## by putting error^2 in lower-right position of VCOV
newVCOV <- VCOV
newVCOV[varPLACE, varPLACE] <- predERROR^2
## create MC simulation matrix
simMAT <- mvrnorm(n = nsim, mu = MU, Sigma = newVCOV, empirical = TRUE)
## evaluate expression on rows of simMAT
EVAL <- try(eval(EXPR, envir = as.data.frame(simMAT)), silent = TRUE)
if (inherits(EVAL, "try-error")) stop("There was an error evaluating the simulations!")
## collect statistics
PRED <- data.frame(predVAL)
colnames(PRED) <- predNAME
FITTED <- predict(object, newdata = data.frame(PRED))
MEAN.sim <- mean(EVAL, na.rm = TRUE)
SD.sim <- sd(EVAL, na.rm = TRUE)
MEDIAN.sim <- median(EVAL, na.rm = TRUE)
MAD.sim <- mad(EVAL, na.rm = TRUE)
QUANT <- quantile(EVAL, c((1 - level)/2, level + (1 - level)/2))
RES <- c(FITTED, MEAN.sim, SD.sim, MEDIAN.sim, MAD.sim, QUANT[1], QUANT[2])
outMAT <- rbind(outMAT, RES)
}
colnames(outMAT) <- c("fit", "mean", "sd", "median", "mad", names(QUANT[1]), names(QUANT[2]))
rownames(outMAT) <- NULL
cat("\n")
return(outMAT)
}
diffpredictNLS <- function(object,newdata,level = 0.95, nsim = 10000, ...){
require(MASS, quietly = TRUE)
## get right-hand side of formula
RHS <- as.list(object$m$formula())[[3]]
EXPR <- as.expression(RHS)
## all variables in model
VARS <- all.vars(EXPR)
## coefficients
COEF <- coef(object)
## extract predictor variable
predNAME <- setdiff(VARS, names(COEF))
lPN<-length(predNAME)
## take fitted values, if 'newdata' is missing
if (missing(newdata)) {
newdata <- eval(object$data)[predNAME]
colnames(newdata) <- predNAME
}
## check that 'newdata' has same name as predVAR
#if (names(newdata)[1] != predNAME) stop("newdata should have name '", predNAME, "'!")
## get parameter coefficients
COEF <- coef(object)
## get variance-covariance matrix
VCOV <- vcov(object)
## augment variance-covariance matrix for 'mvrnorm'
## by adding a column/row for 'error in x'
NCOL <- ncol(VCOV)
ADD1 <- c(rep(0, NCOL*lPN))
ADD1 <- matrix(ADD1, ncol = lPN)
colnames(ADD1) <- predNAME
VCOV <- cbind(VCOV, ADD1)
ADD2 <- c(rep(0, (NCOL + lPN)*lPN))
ADD2 <- matrix(ADD2, nrow = lPN)
rownames(ADD2) <- predNAME
VCOV <- rbind(VCOV, ADD2)
## iterate over all entries in 'newdata' as in usual 'predict.' functions
NR <- nrow(newdata)
respVEC <- numeric(NR)
seVEC <- numeric(NR)
varPLACE <- ncol(VCOV)
## define counter function
counter <- function (i)
{
if (i%%10 == 0)
cat(i)
else cat(".")
if (i%%50 == 0)
cat("\n")
flush.console()
}
outMAT <- NULL
for (i in 1:NR) {
counter(i)
## get predictor values and optional errors
predVAL <- as.numeric(newdata[i, c(predNAME)])
predERROR<-numeric(lPN)
names(predVAL) <- predNAME
names(predERROR) <- predNAME
## create mean vector for 'mvrnorm'
MU <- c(COEF, predVAL)
## create variance-covariance matrix for 'mvrnorm'
## by putting error^2 in lower-right position of VCOV
newVCOV <- VCOV
for(j in 0:(lPN-1)){
newVCOV[varPLACE-j, varPLACE-j] <- (predERROR^2)[lPN-j]
}
## create MC simulation matrix
simMAT <- mvrnorm(n = nsim, mu = MU, Sigma = newVCOV, empirical = TRUE)
## evaluate expression on rows of simMAT
EVAL <- try(eval(EXPR, envir = as.data.frame(simMAT)), silent = TRUE)
if (inherits(EVAL, "try-error")) stop("There was an error evaluating the simulations!")
## collect statistics
PRED <- newdata[i,]
# colnames(PRED) <- predNAME
FITTED <- predict(object, newdata = data.frame(PRED))
# MEAN.sim <- mean(EVAL, na.rm = TRUE)
# SD.sim <- sd(EVAL, na.rm = TRUE)
# MEDIAN.sim <- median(EVAL, na.rm = TRUE)
# MAD.sim <- mad(EVAL, na.rm = TRUE)
QUANT <- quantile(EVAL, c((1 - level)/2, level + (1 - level)/2))
# RES <- c(FITTED, MEAN.sim, SD.sim, MEDIAN.sim, MAD.sim, QUANT[1], QUANT[2])
RES <- c(as.numeric(newdata[i,]),FITTED,QUANT[1], QUANT[2])
outMAT <- rbind(outMAT, RES)
}
# colnames(outMAT) <- c("fit", "mean", "sd", "median", "mad", names(QUANT[1]), names(QUANT[2]))
colnames(outMAT) <- c(names(newdata),"fit", "lower", "upper")
rownames(outMAT) <- NULL
cat("\n")
return(outMAT)
}
####Functions####
##Generate Binary Variables
mutateBin<-function(.data){
.data%>%
mutate(binGlu=ifelse(Glucose=="Hyperglycemic",1,0),
binRes=ifelse(Resveratrol=="Res",1,0),
binNan=ifelse(Nano=="DCD",1,0),
binExp=ifelse(Experiment=="R",1,0))
}
####Library####
library(MASS)
library(ggpubr)
library(ggsignif)
library(ggsci)
library(rstatix)
library(tidyverse)
library(magrittr)
####SA Data Loading and R Data####
fileSA<-paste0("C:/Users/user/Documents/Analysis for Others/Suzette and Anthony/Data",c("","/SuzetteAnthonyData.csv"))
datSA<-as_tibble(read.csv(fileSA[2]))%>%
mutate(Micro="BAE",Nano=ifelse(Surface=="Micro","None","DCD"),Thread="Threaded",RatID=str_glue("SA{ID}"))%>%
select(RatID, Glucose, Resveratrol,Thread, Micro, Nano, Timepoint, Torque)
fileR<-paste0("C:/Users/user/Documents/Experiments/Tau 2 Study/Data",c("","/Reverse Torque Testing Data.csv"))
datR<-as_tibble(read.csv(fileR[2]))%>%
mutate(Resveratrol="PG",RatID=str_glue("R{RatID}"),Timepoint=Time,Glucose="Euglycemic")%>%
select(RatID, Glucose, Resveratrol,Thread, Micro, Nano, Timepoint, Torque)
#Include only data relevant to this experiment
dat<-bind_rows(list(datSA,datR),.id="Experiment")%>%
mutate(across(RatID:Nano,factor),
Experiment=factor(Experiment,levels=c(1,2),labels=c("SA","R")),
Timepoint.F=factor(Timepoint))%>%
filter(Thread=="Threaded",Micro=="BAE",Nano != "NanoTubes")%>%
select(Experiment:Resveratrol|Nano|contains("Time")|Torque)
####Transformation Check####
trans<-boxcox(Torque~interaction(Timepoint.F,Resveratrol,Glucose,Nano,Experiment),data=dat)%>%
as_tibble()%>%
filter(y==max(y))%>%
pull("x")
invTrans<-1/trans
#Can also log transform
dat<-dat%>%
drop_na(Torque)%>%
mutate(tTorque=Torque^trans,
lTorque=log(Torque))%>%
rename(oTorque=Torque)%>%
mutateBin()
##The Below contains code for the plotting of qqPlots for the residuals of linear models
# summary(fit<-lm(tTorque~(Timepoint.F)*(Resveratrol+Glucose+Nano+Experiment),data=dat))
# fitDF<-tibble(Residuals=fit$residuals,Value=fit$fitted.values)%>%
#   bind_cols(fit$model)
#
# fitDF%>%
#   ggplot(aes(x=Value,y=Residuals,colour=Resveratrol))+
#   geom_point()+
#   geom_smooth(method="lm",se=T)
#
# fitDF%>%
#   select(Residuals)%>%
#   arrange(Residuals)%>%
#   mutate(rank=row_number(Residuals),
#          percentile=(rank*1-0.5)/n(),
#          Zscore=qnorm(percentile))%>%
#   ggplot(aes(x=Zscore,y=Residuals))+
#   geom_point()
####Approximate Values####
##Choose Data To analyze
dSet<-"tTorque"
datSum<-dat%>%
group_by(Experiment,Resveratrol,Glucose,Nano,Timepoint)%>%
summarise(across(contains(dSet),list(av=mean,stdDev=sd)))%>%
rename_with(.cols=contains(dSet),.fn= ~ str_to_title(str_extract(.x,"(?<=_)\\w*")))%>%
mutate(NanoLab=ifelse(Nano=="DCD","BAE+DCD","BAE"))
fitDat<-datSum%>%
ungroup()%>%
# filter(Experiment=="SA")%>%
# select(Resveratrol:Glucose|Nano:Av)%>%
select(Experiment:Av)%>%
# pivot_wider(names_from = c(Resveratrol,Glucose,Nano),
#             values_from = Av)
pivot_wider(names_from = c(Experiment,Resveratrol,Glucose,Nano),
values_from = Av)
sumSquares<-crossing(C=seq(0.5,3,by=0.02),Tf=seq(2,8,by=0.1),d=2,Timepoint=c(5,9,14,28))%>%
mutate(Value=C*(1-exp(-(Timepoint-d)/Tf)))%>%
left_join(fitDat)%>%
mutate(across(contains("_"),~(.x-Value)^2))%>%
group_by(C,Tf,d)%>%
summarise(across(contains("_"),~sum(.x)))%>%
ungroup()%>%
pivot_longer(cols = contains("_"))%>%
separate(name,sep="_",into=c("Experiment","Resveratrol","Glucose","Nano"),remove=FALSE)%>%
mutate(across(name:Nano,~factor(.x)))%>%
group_by(name)
ggplot(sumSquares,aes(x=Tf,y=C,fill=log(value)))+
geom_raster()+
facet_wrap(~name)+
geom_contour(aes(z=log(value)),colour="black")
baseParams <- sumSquares%>%
slice_min(value)%>%
ungroup()%>%
filter(Experiment=="SA")
####Fitting Curves(FUNCTIONS)####
##This function generates a basic asymptotic model(F=exp(C)*(1-exp(-(x+D)/Tau)))
##after being provided the strings for the C, D, and Tau parameters
asymp<-function(cStr,dStr,tStr){
paste0("exp(",cStr,")*(1-exp(-(Timepoint-(",dStr,"))/exp(",tStr,")))")
}
##This function generates a dual asymptotic model with 2 periods of growth
##It also allows for selction of the type of torque parameter
##(reg,transformed, log transformed)
##Requires strings for the torque transformation (val), and strings for the
##different parameters (F=C*(1-exp(-(x+D)/Tf))+C*(a)*(1-exp((-(x-28)/Td)))
biPhase<-function(val,cStr,dStr,tfStr,aStr,tdStr){
formStr<-paste0(asymp(cStr,dStr,tfStr),"+binTim*(",aStr,")*",asymp(cStr,"28",tdStr))
if(val=="Torque"){
formStr<-paste0(val,"~",formStr)
return(as.formula(formStr))
}else if(val=="tTorque"){
formStr<-paste0(val,"~pmax(0,(",formStr,"))^",trans)
return(as.formula(formStr))
}else if(val=="lTorque"){
formStr<-paste0(val,"~log(",formStr,")")
print(formStr)
return(as.formula(formStr))
}else(
return("err")
)
}
##This function generates the strings for the various variables along with the
##included binary variables to allow for contrasts based on indices supplied
##and a name for each variable
strGen<-function(termInd,Parameter){
terms<-c("",
"Glu","Res","Nan","Exp",
"GluRes","GluNan","ResNan","NanExp",
"GluResNan")
datRef<-c("",
"*binGlu","*binRes","*binNan","*binExp",
"*binGlu*binRes","*binGlu*binNan","*binRes*binNan","*binNan*binExp",
"*binGlu*binRes*binNan")
len<-length(termInd)
var<-paste0(rep(Parameter,len),terms[termInd],datRef[termInd])
paste(var,collapse = "+")
}
####Fitting Curves####
#initial values
#Reference for Initial Values
sumSquares%>%
slice_min(value)%>%
ungroup()%>%
mutateBin()%>%
arrange(binExp,binNan,binRes,binGlu)%>%
mutate(nVar=binGlu+binRes+binNan+binExp)%>%
arrange(nVar)%>%
arrange(binExp,binRes, binGlu,binNan)
dat<-dat%>%
mutate(binTim=ifelse(Timepoint>=28,1,0))
fittingReference<- read_csv('C:\\Users\\user\\Documents\\My Publications\\SAR\\Analysis\\fittingSoloParams.csv')|>
mutate(suf=if_else(is.na(suf),'',suf))
startingVals <-fittingReference|>
transmute(Par=str_glue("{Par}{suf}={value}"))|>
pull(Par) %>%
paste0(collapse = ',') %>%
paste0('list(',.,')') %>%
parse(text=.) %>%
eval()
biFunc <- fittingReference|>
group_by(Par)|>
mutate(term=str_glue("{Par}{suf}{expression}"))|>
summarise(Par=first(str_glue("{str_to_lower(Par)}Str")),
express=paste0(term,collapse = "+"))|>
pivot_wider(names_from = Par,
values_from = express)%$%
biPhase('tTorque',cStr,dStr,tfStr,aStr,tdStr)
biFunc
startingVals
biFunc <- fittingReference|>
group_by(Par)|>
mutate(term=str_glue("{Par}{suf}{expression}"))|>
summarise(Par=first(str_glue("{str_to_lower(Par)}Str")),
express=paste0(term,collapse = "+"))|>
pivot_wider(names_from = Par,
values_from = express)%$%
biPhase('tTorque',cStr, dStr ,tfStr,aStr,tdStr)
summary(fitAll<-nls(biFunc,
data=dat,
start=startingVals,
control = nls.control(warnOnly = TRUE)))
fittingReference<- read_csv('C:\\Users\\user\\Documents\\My Publications\\SAR\\Analysis\\fittingSoloParams.csv')|>
mutate(suf=if_else(is.na(suf),'',suf))
startingVals <-fittingReference|>
transmute(Par=str_glue("{Par}{suf}={value}"))|>
pull(Par) %>%
paste0(collapse = ',') %>%
paste0('list(',.,')') %>%
parse(text=.) %>%
eval()
biFunc <- fittingReference|>
group_by(Par)|>
mutate(term=str_glue("{Par}{suf}{expression}"))|>
summarise(Par=first(str_glue("{str_to_lower(Par)}Str")),
express=paste0(term,collapse = "+"))|>
pivot_wider(names_from = Par,
values_from = express)%$%
biPhase('tTorque',cStr, dStr ,tfStr,aStr,tdStr)
summary(fitAll<-nls(biFunc,
data=dat,
start=startingVals,
control = nls.control(warnOnly = TRUE)))
fittingReference
startingVals
biFunc
fittingReference<- read_csv('C:\\Users\\user\\Documents\\My Publications\\SAR\\Analysis\\fittingSoloParams.csv')|>
mutate(suf=if_else(is.na(suf),'',suf))
startingVals <-fittingReference|>
transmute(Par=str_glue("{Par}{suf}={value}"))|>
pull(Par) %>%
paste0(collapse = ',') %>%
paste0('list(',.,')') %>%
parse(text=.) %>%
eval()
biFunc <- fittingReference|>
group_by(Par)|>
mutate(term=str_glue("{Par}{suf}{expression}"))|>
summarise(Par=first(str_glue("{str_to_lower(Par)}Str")),
express=paste0(term,collapse = "+"))|>
pivot_wider(names_from = Par,
values_from = express)%$%
biPhase('tTorque',cStr, dStr ,tfStr,aStr,tdStr)
summary(fitAll<-nls(biFunc,
data=dat,
start=startingVals,
control = nls.control(warnOnly = TRUE)))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
load("ST1\\bootstrapAnalysisOutput.RData")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
load("ST1\\bootstrapAnalysisOutput.RData")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
load("bootstrapAnalysisOutput.RData")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
dir()
# load("bootstrapAnalysisOutput.RData")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
dir()
# load("bootstrapAnalysisOutput.RData")
setwd("~/Projects/Coding/github website/RobLiddell.github.io/ST1")
dir()
setwd("C:/Users/user/Documents/Projects/Coding/github website/RobLiddell.github.io")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\user\\Documents\\Projects\\Coding\\github website\\RobLiddell.github.io")
load("ST1\\bootstrapAnalysisOutput.RData")
dir()
load("ST1\\bootstrapAnalysisOutput.RData")
